server:
  error:
    include-message: always
    include-binding-errors: always
  port: 8083

kafka:
  properties:
    num-partitions: 1
    replication-factor: 1
  topic:
    order: "order"
    stock: "stock"
    payment: "payment"

spring:
  kafka:
    # Required connection configs for Kafka producer, consumer, and admin
    bootstrap-servers: pkc-6ojv2.us-west4.gcp.confluent.cloud:9092
    # Required connection configs for Confluent Cloud Schema Registry
    properties:
      bootstrap-servers: pkc-6ojv2.us-west4.gcp.confluent.cloud:9092
      schema.registry.url: https://psrc-kk5gg.europe-west3.gcp.confluent.cloud
      security.protocol: SASL_SSL
      sasl.mechanism: PLAIN
      credentials.source: USER_INFO
      sasl.jaas.config: org.apache.kafka.common.security.plain.PlainLoginModule required username='OIF7NQANRR6MKOLX'   password='FX+y+hbL+0MSur41+rMJpobTv2rHX/UvLOA6DNXyExeHe3OoIVVWG8VrC6IC67tN';
      schema:
        registry:
          url: https://psrc-kk5gg.europe-west3.gcp.confluent.cloud
          basic:
            auth:
              user:
                info: AC2WDR5L5TFTOKH7:PoTBOmSFbdcMBFnP4GKpaSEpje4INp1jJwXk8SCsJl2IzcpP+Yi/tAF6HxICgSuJ
      basic:
        auth:
          credentials:
            source: USER_INFO
    consumer:
      auto-offset-reset: earliest
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: io.confluent.kafka.serializers.KafkaAvroDeserializer
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: io.confluent.kafka.serializers.KafkaAvroSerializer
    streams:
      properties:
        default.key.serde: org.apache.kafka.common.serialization.Serdes$LongSerde
        default.value.serde: io.confluent.kafka.streams.serdes.avro.SpecificAvroSerde
        num.standby.replicas: 1
        num.stream.threads: 2
        max.request.size: 8388608        # 84 MiB
        topic.max.message.bytes: 8388608 # 84 MiB
        topology.optimization: all
        state.dir: /tmp/kafka-streams01
  output:
    ansi:
      enabled: ALWAYS
  application:
    name: "order-ms"
  cloud:
    discovery:
      enabled: false
    compatibility-verifier:
      enabled: false
  messages:
    encoding:
  jpa:
    database: POSTGRESQL
    show-sql: true
    generate-ddl: true
    hibernate:
      ddl-auto: create-drop
    database-platform: org.hibernate.dialect.PostgreSQL9Dialect
    properties:
      hibernate:
        temp:
          use_jdbc_metadata_defaults: false
    open-in-view: false
  datasource:
    url: jdbc:postgresql://localhost:5432/postgres
    username: postgres
    password: postgres

logging:
  pattern.console: "%clr(%d{HH:mm:ss.SSS}){blue} %clr(---){faint} %clr([%15.15t]){yellow} %clr(:){red} %clr(%m){faint}%n"
  level:
    org.apache.kafka.streams.kstream: INFO